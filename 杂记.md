# 之前学习记录的资料

```tex
数据库 Mysql  消息中间件RocketMq 缓存 Redis
搜索引擎 solr/es
```



## 20180825 测试工具

```te
sysbench   benchmark 执行速断
mk-query-digest 一个功能很强大的工具，能分析慢查询日志，也可以对当前的语句进行分析等。
pt-query-digest 安装perl环境 和工具
 https://blog.csdn.net/qq_31879707/article/details/79501249

show variables like '%log_output%';-- 默认是FILE
show variables like '%quer%';
-- log_output 默认是FILE，表示慢查询日志输入至日志文件，可以通过set修改输出为TABLE
-- log_queries_not_using_indexes 默认是OFF，表示是否记录没有使用索引的查询
-- slow_query_log 默认是OFF，表示是否打开慢查询
-- long_query_time默认是 10.000000，表示记录超过时间的慢查询
开启日志
set global slow_query_log = ON;
SET GLOBAL long_query_time = 5;-- 10.000000(需要重连才能看到修改的时间)
-- SET GLOBAL log_queries_not_using_indexes = ON;-- 是否打开看个人需要  
set global log_output='TABLE';-- FILE
set global slow_query_log_file='D:\\dev\\mysql-5.6.41-winx64\\data\\slow.log';
D:\dev\mysql-5.6.41-winx64\data\LS-101028-slow.log
```





##表设计

```tex
1.数据类型选择,能用小的用小的,对于varchar来说约束小好
2.避免字段类型为null
3.表设计遵循 范式(写密集但是关联多)和反范式(没关联,表内容多)
mysql left 函数 相当于截取字符串
select left(NOW(),14);   2018-08-26 17:
4.修改列的属性默认值 用alter table xx alter column xx set xx;(效率比modify 高)
```

##写并发
```te
对于一行的修改会全局的加锁  可以改为随机去修改行数据 并发性能高
```

##索引排列 列的可选择性  单一列值／出现记录总值  值越接近1最好

```sql
select count(distinct (xx))/count(xx) from xx;

```

##索引选择
```tex
B-tree 索引
1.如果要索引的列字符串太长 可以虚拟hash 索引 加字段crc32(Str) 对hash 值索引
2.主键索引外的叫二级索引 保存的是行主键值  通过主键值在去找 聚簇索引 最好是主键为有序插入
3.主键自增的话在并发下 容易产生锁竞争的问题 更改innodb_autoinc_lock_mode 配置
4.索引覆盖 只查询索引列就不用去找主键索引(不用回表)
索引列也是表，如果索引中包括你需要的列，查询结果就找到了，如果没有你需要的列，
索引列中有指针指向表记录的行位置，从表中查询列值。
5.sql_no_cache 禁止缓存 select sql_no_cache xx from xx;
```

##20180831 索引前缀

```tex
1.索引的最左前缀, where xx 和and xx  是困定条件 order by  索引列不能范围查询
2.就是说 where yy order by  xx   (yy)yy 列是最左索引 如果 xx=常量  xx 要是第二索引 或者是yy
3.查询不限制性别  and  sex in('m','f') 加了和不加不影响结果 但是能匹配最左列
4.where 条件使用范围查询 其后的索引列失效
https://blog.csdn.net/zhangjikuan/article/details/78429661
```

##减少索引和数据的碎片化

```tex
1,碎片化的产生  MySQL从你的列表中删除了一行内容，该段空间就会被留空。而在一段时间内的大量删除操作，
会使这种留空的空间变得比存储列表内容所使用的空间更大。如果进行新的插入操作，
MySQL将尝试利用这些留空的区域，但仍然无法将其彻底占用。
https://www.cnblogs.com/zhanglei93/p/6696599.html
2.根据主键去update 和delete 的话就不会锁根节点到索引之间的记录,只是锁行记录
```

##20180908 查询优化

```tex
straight_join 直连jion 指定执行顺序的jion
last_query_cost 查询的状态值 越小越好 show status like '%cost%';
group_concat()  改写in 查询(就是同一组的数据以指定分割符拼接)
optimizer_search_depth 深度查询优化者(可设置大小,在多个表关联的情况下让优化器不采用贪婪模式)
sql 语句QPS(每秒查询次数)可以用jmeter 测试工具来测试
排序优化
索引排序 文件排序(内存排序,磁盘排序)内存快速排序,超过的缓冲区的数据 分块在内存排序写入磁盘,最后磁盘合并
排序算法(单次传输排序)单路排序
sort_buffer_size
exitst 和left join 如果返回的列是一张表的exists 好点否则left join 具体也是
需要注意的是查询匹配到in的列，其后的列在排序中无效，例如，(id,age)为联合索引，现有查询select * from people where id in (1,2,3) order by age;则此时，联合索引无法在排序中生效。
```





##20180909 案例 use index();

```sql
#索引 KEY `begintime` (`begintime`),KEY `dg`(`day`,`group`)   
SELECT round  FROM arena_match_index WHERE `day` = '2010-12-31' AND `group` = 18 AND `begintime` < '2010-12-31 12:14:28'order by begintime LIMIT 1; 
 explain  ref null extra using where
 #问题是 order by 使用`begintime`索引
 SELECT round  FROM arena_match_index use index (dg) WHERE `day` = '2010-12-31' AND `group` = 18 AND `begintime` < '2010-12-31 12:14:28' order by begintime LIMIT 1;
```

##order by 问题

```tex
有时候,order by 字段全部是第一个表,才能做索引排序(并且满足最左索引条件)详情看高性能mysql 5.3.7(使用索引排序)
mysql 常用的hint(sql 就是给优化器按照我们指定的顺序执行)

1、强制索引 FORCE INDEX
SELECT * FROM TABLE1 FORCE INDEX (FIELD1) ⋯
以上的SQL语句只使用建立在FIELD1上的索引，而不使用其它字段上的索引。
2、忽略索引 IGNORE INDEX
SELECT * FROM TABLE1 IGNORE INDEX (FIELD1, FIELD2) ⋯
在上面的SQL语句中，TABLE1表中FIELD1和FIELD2上的索引不被使用。
3、关闭查询缓冲 SQL_NO_CACHE
SELECT SQL_NO_CACHE field1, field2 FROM TABLE1;
有一些SQL语句需要实时地查询数据，或者并不经常使用（可能一天就执行一两次）,这样就需要把缓冲关了,不管这条SQL语句是否被执行过，服务器都不会在缓冲区中查找，每次都会执行它。
4、强制查询缓冲 SQL_CACHE
SELECT SQL_CACHE * FROM TABLE1;
如果在my.ini中的query_cache_type设成2，这样只有在使用了SQL_CACHE后，才使用查询缓冲。
5、优先操作 HIGH_PRIORITY
HIGH_PRIORITY可以使用在select和insert操作中，让MYSQL知道，这个操作优先进行。
SELECT HIGH_PRIORITY * FROM TABLE1;
6、滞后操作 LOW_PRIORITY
LOW_PRIORITY可以使用在insert和update操作中，让mysql知道，这个操作滞后。
update LOW_PRIORITY table1 set field1= where field1= ⋯
7、延时插入 INSERT DELAYED
INSERT DELAYED INTO table1 set field1= ⋯
INSERT DELAYED INTO，是客户端提交数据给MySQL，MySQL返回OK状态给客户端。而这是并不是已经将数据插入表，而是存储在内存里面等待排队。当mysql有空余时，再插入。另一个重要的好处是，来自许多客户端的插入被集中在一起，并被编写入一个块。这比执行许多独立的插入要快很多。坏处是，不能返回自动递增 的ID，以及系统崩溃时，MySQL还没有来得及插入数据的话，这些数据将会丢失。
8、强制链接顺序 STRAIGHT_JOIN
SLECT TABLE1.* FROM TABLE1 STRAIGHT_JOIN TABLE2 WHERE ...
通过hint强制按 TABLE1/TABLE2顺序连接表
9、强制使用临时表 SQL_BUFFER_RESULT
SELECT SQL_BUFFER_RESULT * FROM tbale1
当查询结果集数据比较多时，可以通过SQL_BUFFER_RESULT 强制结果集放到临时表
order by 的列值乱序排则使用文件排序,顺序排的话使用索引.这是索引顺序和列值顺序不一致(索引是有序的).表关联的时
```

## 聚合函数优化

```tex
1.count(*) 统计列行数 为null不统计
 例子 select count(*) from xx where id>5;  
 改写 select (select count(*) from xx)-count(*) from xx where id <=5;
减少了扫描行数
2.group by xx with rollup(分组之后的聚合函数)
3.limt 分页优化 limt(10002,20)数据很大,前面丢掉,效率低,
  select * from xx order by xx limit 50,5; 
  select * from xx inner join(select id from xx order by xx limt 50,5) as using(id);
 延迟关联 
```

 ##自定义变量 @i:=0; 更新之后返回值不需要去查表
```sql
update x set b=now() where id=1;
select b from x where id=1;
update x set b=now() where id=1 and  @o:=now();
select @o;
```

##按唯一主键存在就更新,不存在就修改(插入1,更新2,相同0,行数)

```tex
INSERT INTO ... ON DUPLICATE KEY UPDATE语句
https://blog.csdn.net/analogous_love/article/details/71085001
如果一个表定义有多个唯一键或者主键时，是不安全的容易产生死锁 主要是多条事物并发操作同一条数据 先加读锁 在去加写锁的时候 相互等待对方释放读锁
https://blog.csdn.net/pml18710973036/article/details/78452688
优化union all 查询 一张表查询结果跳过第二张表
least() greatest() 多字段最小和最大函数
```

##Mysql 查看未提交事物和锁

```sql
SELECT * FROM information_schema.INNODB_TRX; #事物
SELECT * FROM information_schema.INNODB_LOCKS;#锁
SELECT * FROM information_schema.INNODB_LOCK_WAITS;#锁等待对应关系
kill 9; 杀掉事物线程id trx_mysql_thread_id
```

##查询超过60秒的事物

```sql
select * from information_schema.innodb_trx where TIME_TO_SEC(timediff(now(),trx_started))>60
set autocommit=1
#https://www.cnblogs.com/lhp2012/p/5315928.html
```

##写锁优化 for update

```sql
BEGIN;//开启事物
select * from unsent_emails where 
owner=0 and status='unsent'
limit 2 for update;//加写锁 读锁 share in mode
update unsent_emails SET
status='claimed' , OWNER=CONNECTION_ID()//连接线程id
where id in(1,4);
COMMIT;
```

##改写尽量用update 去替换
```sql
set autocommit=1;//设置开启自动提交
commit;
update unsent_emails
set status='unsent' , OWNER=0
where OWNER=CONNECTION_ID() and STATUS='claimed'
LIMIT 3;
set autocommit=0;//设置开启手动提交事物 遇到commit 才提交事物
select * from unsent_emails where OWNER=0
and STATUS='unsent';
commit;

```

```tex
这里就是 改成自动提交模式 在update 语句自带提交模式 只要是越快提交事物持有锁的时间就越短,大大减少竞争.
```

##查看事物提交方式
```SQL
show variables like 'autocommit';
```

##优化法则
不做(缓存),少做,快速的做
##20180923 分区partition by

```tex
数据大可以把相关的数据存放在一起,易于维护(crud)
一个表最多有1024个分区,有主键或者唯一索引的列,其他主键列和唯一索引类都包含进来,无法使用外键约束
列子 每一年的销售额存放不同的分区
create table sales(order_date datetime not null,--other columns omitted)engie=innodb parttiton by range(year(order_date))(parttion p_nulls values less than (0),parttion p_2010 values less than (2010),parttion p_2011 values less than (2011),parttion p_catchall values less than maxvalue);
对于year()等日期函数参数非法返回值为null 存放在第一个分区 ,这样子回造成分区过滤失效进行全表
扫描,解决办法是创建无用分区(5.5之前)
5.5之后 分区是可以基于列本身的 如 parttiton by range columns(order_date)
分区列和索引列要匹配
分区查询的时候最好加过滤条件
partitions select * from sales where order_date>'2011-01-01';--只能是在列,函数不行
视图  两种算法 合并(尽量用)和临时表
创建视图(还不是很成熟,需做测试)
create view v_xx as select * from xx where xx='xx' with check option;
with check option 定义的列不能更新
合并是 重写含有视图的查询sql 包含一起
可更新视图 如果定义了group by union 聚合函数和使用的是临时表算法的视图就不能更新
```

##字符集校验

```TEX
select _utf8(编码前缀) 'hello world' COLLATE utf8_bin;
表之间关联的列字段字符集不一样,影响索引的使用(失效).可以使用show warning 来查看
```

##查看表列字段信息

```SQL
SHOW full COLUMNS from student;
```

##查询缓存(建议关闭,开启的话几十兆)
```TEX
如果查询语句中包含任何的不确定的函数(now(),current_date()....),那么在查询缓存中是找不到结果的
缓存失效  缓存碎片,update,内存不足,缓存碎片设置 query_cache_min_res_unit(申请数据结果块)
```

##开启/关闭缓存

```SQL
show VARIABLES like  'query_cache_type';
query_cache_type off/on/demand--sql_cache
query_cache_size #空间单位是字节
```

##使用 PROCEDURE ANALYSE()优化表结构

```SQL
SELECT * FROM xx PROCEDURE ANALYSE(1); 
SELECT ... FROM ... WHERE ... PROCEDURE ANALYSE([ max_elements ,[ max_memory]])
max_elements analyze #查找每一列不同值时所需关注的最大不同值的数量256
```

##20181224最大连接数和当前连接数
```SQL
show status like '%max_connections%'; ##mysql最大连接数
set global max_connections=1000 ##重新设置
show variables like '%max_connections%'; ##查询数据库当前设置的最大连接数
show status like 'Max_used_connections'; ##服务器响应的最大连接数
show status like 'Threads%';
Variable_name Value
Threads_cached    0 ##mysql管理的线程池中还有多少可以被复用的资源
Threads_connected    152 ##打开的连接数
Threads_created    550 ##表示创建过的线程数，如果发现Threads_created值过大的话，表明MySQL服务器一直在创建线程，这也是比较耗资源，可以适当增加配置文件中thread_cache_size值，查询服务器
Threads_running    1 ##激活的连接数，这个数值一般远低于connected数值，准确的来说，Threads_running是代表当前并发数
show variables like 'thread_cache_size'; 
set global thread_cache_size=60;
```

##varchar 字段索引指定长度多少合适 越高重复率低
```sql
select count(distinct left(field, 25))/count(*) from tableName;

```

##20181228 查看表字符集

```SQL
show table status from huhu like  'words';
#查看表字段字符集
show full columns from words;
#修改表字段字符集
alter table test1 modify name char(10) character set xx;
#数据库类型优化建议
select * from words PROCEDURE ANALYSE() ;
#mysql  字符串IP 处理为int
select INET_ATON('192.168.1.1');
```

##awk  查看查询次数,线程连接数,线程运行数

```sql
mysqladmin -uroot ext|awk 
'Queries/{q=$4}/Threads_connected/{c=$4}/Threads_running/{r=$4}END{printf("%d %d %d\n",q,c,r)}'

```



##查看你的数库有多大

```sql
SELECT
  table_schema AS 'Db Name',
  Round( Sum( data_length + index_length ) / 1024 / 1024, 3 ) AS 'Db Size (MB)',
  Round( Sum( data_free ) / 1024 / 1024, 3 ) AS 'Free Space (MB)'
FROM information_schema.tables
GROUP BY table_schema ;
```

##查看表大小

```sql
select concat(round(sum(DATA_LENGTH/1024/1024),2),'M') from information_schema.TABLES where table_schema='dbName' AND table_name='tableName'; 
```

##临时表在如下几种情况被创建:

```TEX
如果group by 的列没有索引,必产生内部临时表,
如果order by 与group by为不同列时,
或多表联查时order by ,group by 包含的列不是第一张表的列,将会产生临时表
distinct 与order by 一起使用可能会产生临时表
```

##  创建临时表和磁盘表

```SQL
show status like '%tmp%';
#临时表空间大小 
show VARIABLES like '%tmp%'

```



##表优化

```TEX
定长与变长分离
如 id int, 占4个字节, char(4) 占4个字符长度,也是定长, time 
即每一单元值占的字节是固定的.
核心且常用字段,宜建成定长,放在一张表.
```

##联合索引的最左原则理解

```tex
为便于理解, 假设ABC各10米长的木板, 河面宽30米.
全值索引是则木板长10米,
Like,左前缀及范围查询, 则木板长6米,
自己拼接一下,能否过河对岸,就知道索引能否利用上.
如上例中, where a=3 and b>10, and c=7,
A板长10米,A列索引发挥作用
A板正常接B板, B板索引发挥作用
B板短了,接不到C板, C列的索引不发挥作用.
如果是 where a=3 and c>10, and b=7,
则是可以用到全部索引的
```

##20190107 gap

```tex
间隙锁和 next-key lock 的引入，帮我们解决了幻读的问题，但同时也带来了一些“困扰”。你如果把隔离级别设置为读提交的话，就没有间隙锁了。使用的是读提交隔离级别加 binlog_format=row 的组合。
ock in share mode 加读锁 其他事物可以加读锁  但是不能加排他锁和修改数据 
for update 不允许其他事务加共享锁或者排它锁读取，更加不允许其他事务修改加锁的行
```

##查看是否开启间隙锁

```SQL
 show variables like 'innodb_locks_unsafe_for_binlog';
```



##20190314 把null 值转换成其他值

```SQL
coalesce(x,0);
#清表
truncate table usable_cash;

```

##通过binlog日志 恢复数据
把binlog 日志导成SQL文件

```sql
mysqlbinlog -v --base64-output=decode-rows mybin.000001 -d exam> test03.sql;
```

命宁行查看binlog日志记录信息

```sql
show binlog events in 'mybin.000001';

```

回复开始节点和结束节点之间的数据也可以是 时间段

```sql
mysqlbinlog mybin.000001 --start-position 1049 --stop-position 1100 | mysql -uroot -p exam ;
```

验证binlog是否开启：

show variables like 'log_bin'; 和 show binary logs;
##查看sql进程
show full PROCESSLIST;
##删除库中的表

```sql
SELECT concat('DROP TABLE IF EXISTS ', table_name, ';')
FROM information_schema.tables
WHERE table_schema = 'gua';
```

##注意点 Online DDL
不要直接做Online DDL，有需要的话，可以用pt-osc工具，避免DDL过程中发生异常导致回滚;
##脏页参数 默认为 75 合适为 25-50

```sql
show VARIABLES like 'innodb_max_dirty_pages_pct';
```



##undo log 清除日志 线程
innodb_purge_threads. 
##查看表碎片大小 看data_free

主要是先看data_length 和index_length 总和 然后看ibd 文件大小

```sql
show table status FROM database LIKE 'table_name';
select concat(round(sum(data_length/1024/1024),2),'MB') as data_length_MB,  
concat(round(sum(index_length/1024/1024),2),'MB') as index_length_MB  
from information_schema.tables where table_schema='db_name'  and table_name ='table_name'; 
```

##ibd文件  查找当前目录下和子目录下的文件

```shell
find . -name ''
sudo find /usr/local/mysql/ -name *.ibd |grep t_user
sudo du -h /usr/local/mysql/data/gua/t_user.ibd
```

##Mac下的MySQL data目录无权访问

```shel
sudo chmod -R a+rwx /usr/local/mysql/data 
```
## CPU利用率和系统负载这两个指标之间是什么关系

```pwd
系统负载代表单位时间内正在运行或等待的进程或线程数，代表了系统的繁忙程度，CPU利用率则代表单位时间内一个线程或进程实时占用CPU的百分比
列子
1 在CPU密集型的情况下，系统的负载未必会高，但CPU的利用率肯定会高，一个线程/进程一直在计算，它对CPU的实时利用率是100%，而系统负载是0.1;
2 I/O密集型的程序来说，有可能CPU的利用率不高，但系统的负载却会非常高，这是因为I/O经常引起阻塞，这样导致很多线程/进程被处于阻塞等待状态，
处于等待的线程或进程也是属于负载线程/进程的。
top  中 Load Avg: 1.42, 1.35, 1.26   代表过去 5 10 15 分钟系统负载 超过5 就是表示负载严重了

```


