## 沈剑-追星笔记

### 1 自己不知道自己的核心竞争力是什么 迷茫？

```pwd
1.你正在做什么，工作来之不易，努力做好手头的事情肯定不是坏事，工作中提升是最快的；
2.工作之外，想成为专家，把领域内的知识，工具，思路搞透。看书，记笔记，和前辈请教，是好的学习方法。
坚持几年，你一定能成为领域内top的专家；
3 给自己定一个目标，例如：每周健身3次，每天学英语半小时，每2周看1本书，每周写一篇读书笔记。
这个浮躁的社会，只要够努力，根本轮不到拼智商。

```

### 2 30亿日志，多条件检索，后台分页查询，有什么好的方案么？

```pwd
结合本例，日志量大，模式固定，建议：
（1）最建议，使用Hive存储，使用索引的方式实现日志后台检索需求；
（2）如果扩展性要求稍高，可以使用ES实现存储与检索，使用水平扩展来存储更大的数据量；
 https://mp.weixin.qq.com/s/3CwbmAIqpq8wSYrZaVTqfw
```

### 3 1000亿身份证信息，MD5查询，5w并发，有什么好的方案么？

```pwd

https://mp.weixin.qq.com/s/Cy2-3NykK5wOP-Fth1aY0g

```

### 4 单库自增主键在后期分库的时候怎么保证现在的新库的ID 和原来的不冲突？

```pwd

假设由单库拆分为3库，可以这么玩：
（1）做一个1主2从数据库集群，相当于每条数据复制成了3份；
（2）将路由算法，设为取模hash算法，%3；
（3）第一个库，%3=0，把余1和余2的uid删掉；
（4）第二个库，%3=1，把余0和余2的uid删掉；
（5）第三个库，%3=2，把余0和余1的uid删掉；
（6）将每个库的自增步长设置为3，这样每个库的id生成就不会重复了；
（7）升级用户中心，按照路由算法查询uid数据；

https://mp.weixin.qq.com/s/HeXfT9bEqqJgqqPWxWh35Q
```

### 5 处理亿级数据的“定时任务”，如何缩短执行时间？

```pwd

总结，对于这类一次性集中处理大量数据的定时任务，优化思路是：
（1）同一份数据，减少重复计算次数；
（2）分摊CPU计算时间，尽量分散处理（甚至可以实时），而不是集中处理；
（3）减少单次计算数据量；
 https://mp.weixin.qq.com/s/aN-M8YcwXNE462HaVrQ6ig

这里 结合工作中的我慧记记录各个时间段的统计
```

### 6 粉丝关系链，10亿数据，如何设计？

```pwd
总结
关系链业务是一个典型的多对多关系，又分为强好友与弱好友
数据冗余是一个常见的多对多业务数据水平切分实践
冗余数据的常见方案有三种
         （1）服务同步冗余
         （2）服务异步冗余
         （3）线下异步冗余
数据冗余会带来一致性问题，高吞吐互联网业务，要想完全保证事务一致性很难，常见的实践是最终一致性
最终一致性的常见实践是，尽快找到不一致，并修复数据，常见方案有三种
         （1）线下全量扫描法
         （2）线下增量扫描法
         （3）线上实时检测法
         
https://mp.weixin.qq.com/s/S1hU7oX7rum01g_Xwixunw

```

### 7 几万条群离线消息，如何高效拉取，会不会丢？

```pwd
总结 
群消息还是非常有意思的，做个简单总结：
(1)群离线消息一般采用拉取模式，只存一份，不需要为每个用户存储离线群msg_id，只需存储一个最近ack的群消息id/time；
(2)为了保证消息可达性，在线消息和离线消息都需要ACK；
(3)离线消息过多，可以分群拉取、分页拉取等优化；
画外音：还可按需拉取，登录不拉取，点进群再拉取。
(4)如果收到重复消息，需要msg_id去重，让用户无感知；
https://mp.weixin.qq.com/s/-KHrxGsBaEvIc4AOkb0_vA

这里 结合工作中的我慧记系统消息推送表设计


```

### 8 盘口数据频繁变化，100W用户如何实时通知？

```pwd
总结
长连接比短连接性能好很多倍
推送量巨大时，推送集群需要与业务集群解耦
推送量巨大时，并发推送与批量推送是一个常见的优化手段
写入量巨大时，水平切分能够扩容，MQ缓冲可以保护数据库
业务复杂，读取量巨大时，加入缓存，定时计算，能够极大降低数据库压力

https://mp.weixin.qq.com/s/QcPicGRkaFENP6IzMRZMaQ

```



